{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floc Analysis\n",
    "\n",
    "This page shows an example of doing an analysis of the watercolumn floc using the CamHDHub and Dask. The goal of this work is to understand changes in the concentration of \"floc\", or bacterial material that has been flushed from the hydrothermal system into the ocean. Changes in floc are an indicator of changes in the hydrothermal system, often as a result of a magmatic event or seismic swarm.\n",
    "\n",
    "This notebook uses [Dask](http://dask.pydata.org/en/latest/) to analyze a large number of frames to establish a proxy for the floc concentration, then plots this value using a two-dimensional multivariate histogram.\n",
    "\n",
    "This version of the floc analysis uses the new regions [metadata](https://github.com/CamHD-Analysis/CamHD_motion_metadata) in CSV format generated by Aaron Marburg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pycamhd.pycamhd as camhd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, progress\n",
    "from daskernetes import KubeCluster\n",
    "cluster = KubeCluster(n_workers=20)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of CamHD files to process and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "csv_url = 'https://raw.githubusercontent.com/CamHD-Analysis/CamHD_motion_metadata/master/datapackage/regions.csv'\n",
    "\n",
    "with requests.Session() as s:\n",
    "    download = s.get(csv_url)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    reader = csv.DictReader(decoded_content.splitlines())\n",
    "    d2_p2_z0 = [r for r in reader if r['scene_tag'] == 'd2_p2_z0']\n",
    "\n",
    "filenames = list(set([d['mov_basename'] for d in d2_p2_z0]))\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a function to return a frame number based on region metadata and a \"relative\" frame number\n",
    "Here we build a list of every frame from a particular scene in a movie using the regions metadata, and assuming that n_frames will be requested, we break this list into groupings of n_frames, and return the first frame from one of these groups based on relative_frame_number. This method quasi-randomly samples the scene, allowing for multiple instances of a scene per movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_frame_number(filename, relative_frame_number, n_frames):\n",
    "    scenes = [r for r in d2_p2_z0 if r['mov_basename'] == filename]\n",
    "    frames = []\n",
    "    for i in scenes:\n",
    "        #range(int(i['start_frame']), int(i['end_frame']))\n",
    "        frames = frames + list(range(int(i['start_frame']), int(i['end_frame'])+1))\n",
    "    return frames[int(round(float(relative_frame_number)/(n_frames-1)*len(frames)))-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a list of frames to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames = 2\n",
    "proc_list = []\n",
    "for filename in filenames:\n",
    "    tmplist = []\n",
    "    tmplist.append('https://rawdata.oceanobservatories.org/files/RS03ASHS/PN03B/06-CAMHDA301/%s/%s/%s/%s.mov'\n",
    "       % (filename[10:14], filename[14:16], filename[16:18], filename))    \n",
    "    for i in range(n_frames):\n",
    "        tmplist.append(real_frame_number(filename, i, n_frames))\n",
    "    proc_list.append(tmplist)\n",
    "proc_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the filter for filtering images in the frequency domain\n",
    "To deal with variations in lighting and high-frequency noise, we filter each subimage using a Butterworth bandpass filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('figure', figsize=(6, 6))\n",
    "d1 = 20; # low cut wavenumber\n",
    "d2 = 400; # high cut wavenumber\n",
    "n = 4;\n",
    "x = np.arange(-1024/2+0.5,1024/2+1-0.5)\n",
    "xx, yy = np.meshgrid(x, x)\n",
    "d = np.sqrt(xx**2+yy**2);\n",
    "bff = (1 - (1./(1 + (d/d1)**(2*n))))*(1/(1 + (d/d2)**(2*n))); # Butterworth bandpass filter\n",
    "imgplot = plt.imshow(bff, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in proc_list:\n",
    "    for j in range(n_frames):\n",
    "        frame = camhd.get_frame(i[0], i[j+1], 'gray16le')\n",
    "        print(frame.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the Dask delayed functions\n",
    "The floc proxy is simply the number of pixels in each filtered subimage that have a value greater than 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask.multiprocessing import get\n",
    "from dask import delayed # , compute\n",
    "\n",
    "#@delayed\n",
    "#def delayed_real_frame_number(filename, relative_frame_number, n_frames):\n",
    "#    return real_frame_number(filename, relative_frame_number, n_frames)\n",
    "\n",
    "@delayed\n",
    "def delayed_get_frame(filename, frame_number, pix_fmt):\n",
    "    return camhd.get_frame(filename, frame_number, pix_fmt)\n",
    "\n",
    "@delayed\n",
    "def delayed_get_floc_proxy(frame):\n",
    "    I = frame[0:1024, 0:1024]\n",
    "    I_fft = np.fft.fft2(I);\n",
    "    I_fft_shift = np.fft.fftshift(I_fft);\n",
    "    I_fft_shift_filt = I_fft_shift*bff; # filter with the Butterworth filter\n",
    "    I_fft_filt = np.fft.ifftshift(I_fft_shift_filt);\n",
    "    I_filt = np.fft.ifft2(I_fft_filt);\n",
    "    fp = (np.absolute(I_filt)>4000).sum()\n",
    "    #print(fp)\n",
    "    return fp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the floc_proxy using Dask parallelization\n",
    "We use Dask to handle load balancing among processors on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "delayed_floc_proxy = []\n",
    "#n_frames = 2 # number of frames to use in for each video\n",
    "#relative_frame_numbers = range(0,n_frames)\n",
    "keys = []\n",
    "\n",
    "results = []\n",
    "for element in proc_list:\n",
    "    filename = element[0]\n",
    "    for i in range(n_frames):\n",
    "        frame_number = element[i+1]\n",
    "        frame = delayed_get_frame(filename, frame_number, 'gray16le')\n",
    "        dfp = delayed_get_floc_proxy(frame)\n",
    "        results.append(dfp)\n",
    "        keys.append((filename, frame))\n",
    "    \n",
    "    #for relative_frame_number in relative_frame_numbers:\n",
    "    #    frame_number = delayed_real_frame_number(filename, relative_frame_number, n_frames)\n",
    "    #    frame = delayed_get_frame('/data/' + filename + '.mov', frame_number, 'gray16le')\n",
    "    #    delayed_floc_proxy.append(delayed_get_floc_proxy(frame))\n",
    "# floc_proxy = compute(*delayed_floc_proxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.dot import dot_graph\n",
    "dot_graph(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dask.compute(results[:200])\n",
    "results_all = dict(zip(keys[:200], results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.multiprocessing\n",
    "\n",
    "#     dask.compute(results[:300])\n",
    "    \n",
    "    \n",
    "with dask.set_options(get=dask.get):\n",
    "    for key, res in zip(keys[200:300], results[200:300]):\n",
    "        print(key)\n",
    "        res.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time results_persisted = dask.compute(results[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_persisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_computed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a timestamp for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, math\n",
    "import matplotlib.dates as dates\n",
    "frame_timestamp = []\n",
    "for filename in filenames:\n",
    "    for relative_frame_number in relative_frame_numbers:\n",
    "        frame_number = real_frame_number(filename, relative_frame_number, n_frames)\n",
    "        year = int(filename[10:14])\n",
    "        month = int(filename[14:16])\n",
    "        day = int(filename[16:18])\n",
    "        hour = int(filename[19:21])\n",
    "        minute = int(math.floor(frame_number/29.95/60))\n",
    "        second = int(math.floor(frame_number/29.95-minute*60))\n",
    "        microsecond = int(round((frame_number/29.95-second-minute*60)*1000000))\n",
    "        dt = datetime.datetime(year, month, day, hour, minute, second, microsecond)           \n",
    "        frame_timestamp.append(dates.date2num(dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a two-dimensional multivariate histogram of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', size=11)\n",
    "fig, ax = plt.subplots();\n",
    "fig.set_size_inches(14, 6);\n",
    "fig.frameon = False\n",
    "hb1 = ax.hexbin(frame_timestamp, floc_proxy, vmin=0, vmax=2, bins='log', linewidths=0.25,\n",
    "  gridsize=(240,80), mincnt=1, cmap=plt.cm.BuPu)\n",
    "fig.colorbar(hb1)\n",
    "ax.set_ylim([0, 8000])\n",
    "ax.set_xlim([frame_timestamp[0],frame_timestamp[-1]])\n",
    "ax.yaxis.grid(True)\n",
    "ax.xaxis.grid(True)\n",
    "months = dates.MonthLocator()  # every month\n",
    "monthsFmt = dates.DateFormatter('%b %Y')\n",
    "ax.xaxis.set_major_locator(months)\n",
    "ax.xaxis.set_major_formatter(monthsFmt)\n",
    "plt.ylabel('Floc Proxy Value');\n",
    "\n",
    "# print\n",
    "#fig_dpi = 300\n",
    "#fig.savefig('floc_hexbin.png', bbox_inches='tight', transparent=True,\n",
    "#  pad_inches=0, orientation='portrait', format='png', dpi=fig_dpi);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting in late-June a large \"floc event\" occurs where the floc proxy values increase on average by nearly a factor of ten. The cause of this floc event is being investigated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "PyCamHD: https://github.com/tjcrone/pycamhd<br>\n",
    "CamHDHub: https://github.com/tjcrone/camhdhub<br>\n",
    "Raw Data Archive: https://rawdata.oceanobservatories.org/files/RS03ASHS/PN03B/06-CAMHDA301/<br>\n",
    "AGU Abstract: https://agu.confex.com/agu/fm16/meetingapp.cgi/Paper/192670<br>\n",
    "AGU Poster: https://drive.google.com/open?id=0B-dWW4GM434obGpTM0FZME10Nkk<br>\n",
    "Dask: http://dask.pydata.org/en/latest/"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
